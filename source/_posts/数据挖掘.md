---
title: 项目书写规范
date: 2024-04-06 10:00:00
author: 岁漫
img: /images/k1.jpg
top: true
hide: false
cover: true
coverImg: /images/k1.jpg
toc: false
mathjax: false
summary: 跟河工智叟学数据挖掘
categories: 大三课程整理
tags:
  - 数据挖掘
---

# 数据预处理

## 数据质量三要素

准确性、完整性、一致性、时效性、可信性和可解释性。

## 数据预处理的的主要任务

* 数据清理：例程通过填写缺失的值，光滑噪声数据，识别或删除离群点
* 数据集成：代表同一概念的属性在不同的数据库中可能具有不同的名字，导致不一致性和冗余。
* 数据归约：（为分析选取的数据集是巨大的，这会降低数据挖掘的速度）数据规约得到数据集的简化表示，它小得多，但能够产生同样的（或几乎同样的）分析结果。数据归约策略包括维归约和数值归约。
  * 维归约：使用数据编码方案，以便得到原始数据的简化或“压缩”表示。例子包括数据压缩技术（例如，小波变换和主成分分析），以及属性子集选择（例如，去掉不相关的属性）和属性构造（例如，从原来的属性集导出更有用的小属性集）
  * 数值归约：使用参数模型（例如，回归和对数线性模型）或非参数模型（例如，直方图、聚类、抽样或数据聚集），用较小的表示取代数据

## 数据清理

### 处理缺失值

1. 忽略元组：当缺少类标号时通常这样做（假定挖掘任务涉及分类）。除非元组有多个属性缺少值，否则该方法不是很有效。当每个属性缺失值的百分比变化很大时，它的性能特别差。采用忽略元组，你不能使用该元组的剩余属性值。
2. 人工填写缺失值：缺失很多值时，行不通。
3. 使用一个全局常量填充缺失值：如unknown,∞等代替。
4. 使用**属性**的中心度量（如均值或中位数）填充缺失值：对于正常的（对称的）数据分布而言，可以使用均值，而倾斜数据分布应该使用中位数
5. 使用与**给定元组属于同一类**的所有样本的属性均值或中位数：，如果将顾客按credit_rish 分类，则用具有相同信用风险的顾客的平均收入替换 incore 中的缺失值。如果给定类的数据分布是倾斜的，则中位数是更好的选择。
6. (**最常用**)使用最有可能的值填充：用回归/使用贝叶斯形式化方法的基于推理的工具或决策树归纳确定。

***⚠️注意***：缺失值并不意味数据错误，比如要求提供驾照号码，一些人没有驾照，自然不填。

### 处理噪声数据

噪声：是被测量的变量的随机误差或方差。

1. 分箱：将一些有序的值分到不同的箱中，采用箱均值、箱中位数、箱边界方法来光滑“近邻”的值。

   划分为（等频的）箱：箱1：4,8,15、箱2:21.21,24、箱3:25.28,34

   用箱均值光滑：箱1：9,9,9、箱2:22,22,22、箱3：29,29,29

   用箱边界光滑：箱1：4,4,15、箱2:21.21,24、箱3：25,25,34

2. 回归：使用一种函数拟合数据来光滑数据。

3. 离群点分析：通过如聚类来检测离群点。

*许多数据光滑的方法也用于数据离散化和数据归约*

### 数据清理作为一个过程

*元数据：关于数据性质的知识（关于数据的数据）*

偏差检测：利用元数据对数据进行检测，还有一些规则：

1. 唯一性规则：给定属性值都必须不同
2. 连续性～：属性的最低和最高值之间没有缺失的值，还必须唯一
3. 空值规则：说明空白、问号、特殊符号等符号的使用

还有一些商业工具帮助检测：数据清洗工具、数据审计工具、数据迁移工具。

## 数据集成

*合并来自多个数据源的数据，小心集成有助于减少结果数据集的冗余和不一致。提高后期数据处理的准确性和速度。*

### 实体识别问题

对于不同数据源中同一实体的类名、属性名或属性值取值范围不同的集成。

### 冗余和相关分析

一个属性的值是由其他属性值导出或计算出，那这个数据就是冗余的。一些冗余可以被相关分析检测到，对于标称数据，使用卡方检验，对于数值属性，使用*相关系数和协方差*，都可以用来评估一个属性的值，如何随另一个变化。

#### 标称数据的x°（卡方）相关检验

p63，根据卡方检验两个属性是否独立

#### 数值相关的相关系数

P63，计算两个属性的相关系数

#### 数值数据的协方差

评估两个属性如何一起变化，协方差为0蕴含独立性

### 元组重复

元组级检测重复

### 数据值冲突的检测与处理

对于同一实体，属性值不同（可能由于表示、尺度或编码不同而导致的）

## 数据归约

*将海量数据集进行规约表示，使其变小很多，但是仍接近于保持原始数据的完整性。

### 数据归约的策略概述

1. 维归约

   减少所考虑的随机变量或属性的个数。方法包括小波变换和主成分分析，把原始数据变换或投影到较小的空间。

2. 数量归约

   用替代的、较小的数据表示形式替换原数据。

3. 数据压缩

   使用变换，以便得到愿数据的归约或“压缩”表示。

   无损：愿数据能够从压缩后的数据重构，而不损失信息。

   有损：只能近似重构。

### 小波变换

1. 去噪
2. 突出目标
3. 多分辨分析（横向、竖向）
4. 高效
5. 只能低维

### 主成分分析（PCA）

最常用的线性成分分析方法

寻找数据的主轴方向，由主轴构成一个新的坐标系（维数可比原来低），然后数据由原坐标向新坐标系投影。

<img src="https://raw.githubusercontent.com/suimanman/imgs/main/sjwj1.png" style="zoom:33%;" />

### 属性子集选择

删除不相关或冗余的属性来减少数据量。属性子集选择的目标是找出最小属性集，使得数据类的概率分布尽可能地接近使用所有属性得到的原分布。在缩小的属性集上挖掘还有其他的优点：它减少了出现在发现模式上的属性数目，使得模式更易于理解。

> Data Reduction 2: Numerosity Reduction
>
> 1. Parametric methods（回归）
> 2. Non-parametric methods

### 回归和对数线性模型：参数化数据规约

>对数据建模，对其参数化，模拟到函数中。
>
>包括线性回归、多元回归、对数线性模型。

### 直方图

使用分箱来近似数据分布。

划分规则：

* 等宽：每个桶的宽度区间一致
* 等频：使得每个桶的频率粗略的为常数（即，每个桶大致包含相同个数的近邻数据样本）

### 聚类

### 抽样

允许用数据小得多的随机样本（子集）表示大型数据集。

抽样方法

* 无放回简单随机抽样

  概率都是1/n

* 有放回简单随机抽样

* 簇抽样

* 分层抽样

  划分成几个互不相干的部分，称做“层”

## 数据变换与数据离散化

### 数据变换策略

1. 光滑：去噪，包括分箱、回归和聚类。
2. 属性构造：可以由给定的属性构造新的属性并添加到属性集中，以帮助挖掘过程。
3. 聚集：对数据进行汇总或聚集
4. 规范化：按比例缩放，使之落到一个特定的区间。
5. 离散化：数值属性的原始值用区间标签或概念标签代替。
6. 由标称数据产生概念分层

### 通过规范化变换数据

最大-最小规范化：

<img src="https://raw.githubusercontent.com/suimanman/imgs/main/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/image-20240415104757847.png" style="zoom:50%;" />

其中包括：

<img src="https://raw.githubusercontent.com/suimanman/imgs/main/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/image-20240415104923206.png" style="zoom:50%;" />

<img src="https://raw.githubusercontent.com/suimanman/imgs/main/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/image-20240415105309157.png" style="zoom:50%;" />

### 分箱离散化

### 直方图离散化

等宽直方图、等频直方图

### 通过聚类、决策树和相关分析离散化

### 标称数据的概念分层产生

## 数据仓库与联机分析处理

⚠️考试：

<img src="https://raw.githubusercontent.com/suimanman/imgs/main/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%88%AA%E5%B1%8F2024-04-15%2011.25.22.png" style="zoom:50%;" />

