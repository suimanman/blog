---
title: 机器视觉
date: 2024-04-08 14:25:00
author: 岁漫
img: /images/2.jpg
top: true
hide: false
cover: true
coverImg: /images/2.jpg
toc: false
mathjax: false
summary: 简单记录
categories: 大三课程
tags:
  - 计算机视觉
---

# 目标检测

## 任务

找到图像中所有感兴趣的物体，包含物体定位和物体分类两个子任务。

1. 分类（Classification）：即是将图像结构化为某一类别的信息，用事先确定好的类别(string)或实例ID来描述图片。这一任务是最简单、最基础的图像理解任务，也是深度学习模型最先取得突破和实现大规模应用的任务。其中，ImageNet是最权威的评测集，每年的ILSVRC催生了大量的优秀深度网络结构，为其他任务提供了基础。在应用领域，人脸、场景的识别等都可以归为分类任务。
2. 检测（Detection）：分类任务关心整体，给出的是整张图片的内容描述，而检测则关注特定的物体目标，要求同时获得这一目标的类别信息和位置信息。相比分类，检测给出的是对图片前景和背景的理解，我们需要从背景中分离出感兴趣的目标，并确定这一目标的描述（类别和位置），因而，检测模型的输出是一个列表，列表的每一项使用一个数据组给出检出目标的类别和位置（常用矩形检测框的坐标表示）。
3. 分割（Segmentation）：分割包括语义分割（semantic segmentation）和实例分割（instance segmentation），前者是对前背景分离的拓展，要求分离开具有不同语义的图像部分，而后者是检测任务的拓展，要求描述出目标的轮廓（相比检测框更为精细）。分割是对图像的像素级描述，它赋予每个像素类别（实例）意义，适用于理解要求较高的场景，如无人驾驶中对道路和非道路的分割。

## 难点

1. 鲁棒识别

   光照影响、物体姿态影响、类内差异、类间相似性等

2. 计算量大

3. 小样本条件下学习

## 数据集

<img src="/Users/wangmeice/Library/Application Support/typora-user-images/image-20240429142322443.png" alt="image-20240429142322443" style="zoom: 33%;" />

# 基于深度学习的目标检测算法

<img src="/Users/wangmeice/Library/Application Support/typora-user-images/image-20240429143630226.png" alt="image-20240429143630226" style="zoom: 50%;" />

两阶段：

1. 区域建立
2. 特征提取

单阶段：

无需区域建立，直接对图片进行特征提取。

## 单阶段

单阶段模型没有中间的区域检出过程，直接从图片获得预测结果，也被成为Region-free方法。

## YOLO

论文链接：

[You Only Look Once: Unified, Real-Time Object Detection]: https://arxiv.org/abs/1506.02640

YOLO是单阶段方法的开山之作。它将检测任务表述成一个统一的、端到端的回归问题，并且以只处理一次图片同时得到位置和分类而得名。

<img src="/Users/wangmeice/Library/Application Support/typora-user-images/image-20240429145247209.png" alt="image-20240429145247209" style="zoom: 50%;" />

### YOLO的工作流程

1.准备数据：将图片缩放，划分为等分的网格，每个网格按跟Ground Truth的IoU分配到所要预测的样本。

2.卷积网络：由GoogLeNet更改而来，每个网格对每个类别预测一个条件概率值，并在网格基础上生成B个box，每个box预测五个回归值，四个表征位置，第五个表征这个box含有物体（注意不是某一类物体）的概率和位置的准确程度（由IoU表示）。测试时，分数如下计算：

![image-20240429150033097](/Users/wangmeice/Library/Application Support/typora-user-images/image-20240429150033097.png)

等式左边第一项由网格预测，后两项由每个box预测，以条件概率的方式得到每个box含有不同类别物体的分数。 因而，卷积网络共输出的预测值个数为S×S×(B×5+C)，其中S为网格数，B为每个网格生成box个数，C为类别数。

3.后处理：使用NMS（Non-Maximum Suppression，非极大抑制）过滤得到最后的预测框

# 主要研究方向

![image-20240429151309114](/Users/wangmeice/Library/Application Support/typora-user-images/image-20240429151309114.png)

交并比：IOU=AnB/AUB

小目标检测：可用特征少，容易受外部干扰

目标检测评价指标

精准率：在所有预测为正的样本中实际为正的样本的概率

召回率：在实际为正的样本中被预测为正样本的概率

# 小目标的检测

1. 数据增强
2. 多尺度学习
3. 上下文学习
4. 无锚机制锚框机制

# 运动分析

## 运动分类和表达

